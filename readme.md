# Исследование обучения LLM-агента логическому выводу

Исследование эффективности алгоритма GRPO (Group Relative Policy Optimization) для обучения языковых моделей решению логических задач формата ЕГЭ №2.

##  Описание проекта

Данный проект направлен на улучшение способности больших языковых моделей (LLM) к логическому мышлению через обучение с подкреплением. В качестве тестовых задач используются задания формата ЕГЭ по информатике (задача №2), что позволяет объективно оценить прогресс модели.

##  Быстрый старт

### Установка зависимостей

```bash
pip install -r requirements.txt
```

### Полный цикл обучения и оценки

1. **Генерация тестовых наборов данных**
   ```bash
   python scripts/build_test_sets.py
   ```

2. **Проверка математической уникальности датасетов**
   ```bash
   python scripts/verify_datasets.py
   ```

3. **Оценка базовой модели (до обучения)**
   ```bash
   python scripts/evaluate_baseline.py
   ```

4. **Запуск обучения с использованием GRPO**
   ```bash
   python scripts/train_grpo.py
   ```

5. **Финальное тестирование обученной модели**
   ```bash
   python scripts/evaluate_final.py
   ```

6. **Сравнительный анализ результатов**
   ```bash
   python scripts/final_comparison.py
   ```

## Настройка для различных платформ

### macOS (Apple Silicon)

Проект изначально разработан и протестирован на чипах Apple M-серии. Используется устройство `mps`:

```python
device = "mps"
```

### Windows / Linux

Для совместимости с другими платформами необходимо изменить выбор устройства в скриптах:

```python
device = "cuda" if torch.cuda.is_available() else "cpu"
```

#### Дополнительные требования для Windows

Для работы с квантованными моделями на Windows может потребоваться установка специальной версии библиотеки:

```bash
pip install bitsandbytes-windows
```

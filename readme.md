## Подготовка модели

Для работы скриптов необходимы локальные веса модели `Qwen2.5-1.5B-Instruct`. Файлы модели должны быть размещены в директории проекта по пути: `models/qwen_model/`.

### Способы получения модели:

**Способ 1: Автоматический (через Python)**

Запустите предустановленный скрипт, который скачает модель напрямую с Hugging Face:

```bash
python scripts/download_model.py
```

**Способ 2: Прямая загрузка с Hugging Face**

Перейдите на страницу модели [Qwen/Qwen2.5-1.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct) и скачайте содержимое репозитория. Основной файл весов — `model.safetensors` (около 3.1 ГБ). Разместите скачанные файлы в директории `models/qwen_model/`.

**Способ 3: Загрузка через Google Colab**

В случае ограничений скорости сети, рекомендуется использовать Google Colab для выполнения `snapshot_download`. После загрузки файлы следует упаковать в архив, сохранить на Google Диск и затем скачать в локальную папку проекта.

**Важно**: Перед запуском убедитесь, что в `models/qwen_model/` присутствуют файлы `config.json`, `tokenizer.json` и `model.safetensors`.

Итоговая структура должна выглядеть так:
```
ege_task2_rl/
├── models/
│   └── qwen_model/
│       ├── model.safetensors
│       ├── config.json
│       ├── tokenizer.json
│       └── ...
├── scripts/
└── ...
```

## Быстрый старт

### 1. Установка зависимостей

Рекомендуется использование виртуального окружения (Python 3.10+).

```bash
pip install -r requirements.txt
```

### 2. Полный цикл обучения и оценки

1. **Генерация тестовых наборов данных**
   ```bash
   python scripts/build_test_sets.py
   ```

2. **Проверка математической уникальности датасетов**
   ```bash
   python scripts/verify_datasets.py
   ```

3. **Оценка базовой модели (Baseline)**
   ```bash
   python scripts/baseline_eval.py
   ```

4. **Запуск обучения с использованием GRPO**
   ```bash
   python scripts/train_grpo.py
   ```

5. **Финальное тестирование обученной модели**
   ```bash
   python scripts/evaluate_final.py
   ```

6. **Сравнительный анализ результатов**
   ```bash
   python scripts/evaluate_final.py
   ```

## Важные детали реализации

- **Математическая корректность**: Среда гарантирует единственность решения каждой задачи за счет встроенного алгоритмического решателя (Solver), который проверяет фрагменты таблиц на непротиворечивость перед сохранением.

- **Требования к памяти**: Для обучения (GRPO) требуется минимум 16 ГБ оперативной памяти (в случае Apple Silicon) или 12 ГБ VRAM (в случае NVIDIA GPU).

- **Время обучения**: Цикл из 250 шагов на процессоре M5 занимает приблизительно 8.5 часов.

- **Формат ответа**: Модель обучается использовать теги `<think>` для цепочки рассуждений и `<answer>` для финального сопоставления переменных.

## Настройка для различных платформ

### macOS (Apple Silicon)

Проект изначально разработан и протестирован на чипах Apple M-серии. Используется устройство `mps`:

```python
device = "mps"
```

### Windows / Linux

Для совместимости с другими платформами необходимо изменить выбор устройства в скриптах:

```python
device = "cuda" if torch.cuda.is_available() else "cpu"
```

### Дополнительные требования для Windows

Для работы с квантованными моделями на Windows может потребоваться установка специальной версии библиотеки:

```bash
pip install bitsandbytes-windows
```

import json
import os
import sys
import torch
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(PROJECT_ROOT)

from base.data import Data
from verifiers.ege_logic_verifier import EGELogicVerifier

# --- –ø—É—Ç–∏ ---

BASE_MODEL_PATH = os.path.join(PROJECT_ROOT, "models", "qwen_model")
FINETUNED_PATH = os.path.join(PROJECT_ROOT, "scripts", "models", "qwen-ege-logic-final")
DATASETS_DIR = os.path.join(PROJECT_ROOT, "scripts", "datasets")

SYSTEM_PROMPT = """Respond in the following format:
<think>
...
</think>
<answer>
...
</answer>"""

device = torch.device("mps")


def evaluate_dataset(file_name, model, tokenizer, verifier):
    path = os.path.join(DATASETS_DIR, file_name)

    if not os.path.exists(path):
        print(f"—Ñ–∞–π–ª {file_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {path}")
        return None

    print(f"\n –æ—Ü–µ–Ω–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {file_name}")
    correct = 0

    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    total = len(lines)
    pbar = tqdm(lines, desc=f"Level: {file_name}")

    for i, line in enumerate(pbar):
        data_dict = json.loads(line)
        data = Data(**data_dict)


        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": data.question},
        ]

        input_text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        inputs = tokenizer([input_text], return_tensors="pt").to(device)

        with torch.inference_mode():
            outputs = model.generate(
                **inputs,
                max_new_tokens=512,
                do_sample=False,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id,
            )

        generated_ids = outputs[0][len(inputs.input_ids[0]):]
        response = tokenizer.decode(generated_ids, skip_special_tokens=True)


        if verifier.verify(data, response):
            correct += 1

        # –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        pbar.set_postfix({"acc": f"{(correct / (i + 1)) * 100:.1f}%"})

        # –≤—ã–≤–æ–¥ –ø–µ—Ä–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
        if i == 0:
            tqdm.write(f"\nüìù –ü–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è {file_name}:")
            tqdm.write(f"Response: {response[:200]}...")
            tqdm.write(f"Gold Answer: {data.answer}\n")

    accuracy = (correct / total) * 100
    return accuracy


def main():
    # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π
    if not os.path.exists(BASE_MODEL_PATH) or not os.path.exists(FINETUNED_PATH):
        print(f"–ø—Ä–æ–≤–µ—Ä—å –ø—É—Ç–∏.")
        print(f"Base: {BASE_MODEL_PATH} ({os.path.exists(BASE_MODEL_PATH)})")
        print(f"Final: {FINETUNED_PATH} ({os.path.exists(FINETUNED_PATH)})")
        return

    print(f"–∑–∞–≥—Ä—É–∑–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, local_files_only=True)
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_PATH,
        torch_dtype=torch.bfloat16,
        device_map="mps",
        local_files_only=True
    )

    print(f"–Ω–∞–ª–æ–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ GRPO-–∞–¥–∞–ø—Ç–µ—Ä–∞ (LoRA)...")
    model = PeftModel.from_pretrained(
        base_model,
        FINETUNED_PATH,
        local_files_only=True
    ).to(device)

    model.eval()
    print("–º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≥–æ—Ç–æ–≤–∞ –∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Ç–µ—Å—Ç–∞–º!")

    verifier = EGELogicVerifier()
    test_files = ["test_easy.jsonl", "test_medium.jsonl", "test_hard.jsonl"]
    final_results = {}

    for file in test_files:
        acc = evaluate_dataset(file, model, tokenizer, verifier)
        if acc is not None:
            final_results[file] = acc


    print("\n" + "=" * 45)
    print(f"{'DATASET (AFTER RL)':<25} | {'ACCURACY':<10}")
    print("-" * 45)
    for file, acc in final_results.items():
        print(f"{file:<25} | {acc:.2f}%")
    print("=" * 45)


if __name__ == "__main__":
    main()